import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV
from sklearn.ensemble import RandomForestClassifier

df_train=pd.read_csv('train.csv')
df_test=pd.read_csv('test.csv')

df_train=pd.read_csv(train.csv)
df_test=pd.read_csv(test.csv)

df_train.info()

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB
#######find out how many columns have the value missing

#######if some features is no need for the label, then you can drop the features
df_train.drop(['Name','Ticked','Cabin'],inplace=True,axis=1)
df_train['Age']=df_train['Age'].fillna(df_train['Age'].mean())   ##########use mean value to fill the Nan of 'Age'

df_train=df_train.dropna()

df_train.info()
<class 'pandas.core.frame.DataFrame'>
Int64Index: 889 entries, 0 to 890
Data columns (total 9 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  889 non-null    int64  
 1   Survived     889 non-null    int64  
 2   Pclass       889 non-null    int64  
 3   Sex          889 non-null    object 
 4   Age          889 non-null    float64
 5   SibSp        889 non-null    int64  
 6   Parch        889 non-null    int64  
 7   Fare         889 non-null    float64
 8   Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(2)
memory usage: 69.5+ KB

label_s=df_train['Sex'].unique().tolist()
label_e=df_train['Embarked'].unique().tolist()

df_train['Sex']=df_train['Sex'].apply(lambda x : label_s.index(x))
df_train['Embarked']=df_train['Embarked'].apply(lambda x : label_e.index(x)) ####transfer object to number

x=df_train.loc[:,df_train.columns !='Survived']
y=df_train.loc[:,df_train.columns == 'Survived']

rfc=RandomForestClassifier(random_state=10)
score=cross_val_score(rfc,x,y,cv=10).mean()
score

0.8009193054136874
########find the best n_estimators
scores=[]
for i in range(1,51):
    rfc=RandomForestClassifier(n_estimators=i,random_state=10)
    score=cross_val_score(rfc,x,y,cv=10).mean()
    scores.append(score)
print('The highest score is {} and the i is {}:'.format(max(scores),scores.index(max(scores))+1))

The highest score is 0.8155515832482125 and the i is 32

plt.plot(range(1,51),scores)
plt.show()

#######find the best max_depth
scores=[]
for i in range(1,11):
    rfc=RandomForestClassifier(n_estimators=32,max_depth=i,random_state=10)
    score=cross_val_score(rfc,x,y,cv=10).mean()
    scores.append(score)
print('the best score {} and the max_depth {}'.format(max(scores),scores.index(max(scores))+1))

the best score 0.8290602655771195 and the max_depth 6

params={'min_samples_leaf':range(1,11,1)}
rfc=RandomForestClassifier(n_estimators=32,max_depth=6,random_state=10)
GS=GridSearchCV(rfc,params,cv=10)
GS.fit(x,y)

GS.best_params_
{'min_samples_leaf': 2}
GS.best_score_
0.8335418794688456

params={'min_samples_split':range(2,22,1)}
rfc=RandomForestClassifier(n_estimators=32,max_depth=6,min_samples_leaf=2,random_state=10)
GS=GridSearchCV(rfc,params,cv=10)
GS.fit(x,y)

GS.best_params_
{'min_samples_split': 2}

params={'max_features':np.arange(0,8,1)}
rfc=RandomForestClassifier(n_estimators=32,max_depth=6,min_samples_leaf=2,min_samples_split=2,random_state=10)
GS=GridSearchCV(rfc,params,cv=10)
GS.fit(x,y)

GS.best_params_
{'max_features': 5}

rfc=RandomForestClassifier(n_estimators=32,max_depth=6,min_samples_leaf=2,min_samples_split=2,max_features=5,random_state=10)
score=cross_val_score(rfc,x,y,cv=10).mean()
score
0.8346271705822266

df_test
label_s=df_test['Sex'].unique().tolist()
label_e=df_test['Embarked'].unique().tolist()

df_test['Sex']=df_test['Sex'].apply(lambda x:label_s.index(x))
df_test['Embarked']=df_test['Embarket'].apply(lambda x : label_e.index(x))

df_test['Age']=df_test['Age'].fillna(df_test['Age'].mean())
df_test=df_test.dropna()

rfc.fit(x,y)
pre=rfc.predict(df_test)
prediction=pd.DataFrame(pre,columns=['Survived'])

result=pd.concat([df_test,prediction],axis=1)

